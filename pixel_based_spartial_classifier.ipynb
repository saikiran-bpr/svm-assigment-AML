{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339acfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install opencv-python numpy scikit-learn joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c522c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Training Data...\n",
      "Processing 50 images with -1 jobs...\n",
      "Loaded 100000 samples in 0.75s\n",
      "Loading Validation Data...\n",
      "Processing 20 images with -1 jobs...\n",
      "Training SVM...\n",
      "Running Inference...\n",
      "\n",
      "=== Optimized Method 2: RGB + (x,y), LinearSVC ===\n",
      "Accuracy : 0.9350\n",
      "Precision: 0.0536\n",
      "Recall   : 0.0024\n",
      "Training time : 0.0393s\n",
      "Inference time: 0.0005s\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import glob\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from joblib import Parallel, delayed\n",
    "import os\n",
    "\n",
    "TRAIN_IMG_DIR = \"./ADEChallengeData2016/images/training/\"\n",
    "TRAIN_ANN_DIR = \"./ADEChallengeData2016/annotations/training/\"\n",
    "VAL_IMG_DIR   = \"./ADEChallengeData2016/images/validation/\"\n",
    "VAL_ANN_DIR   = \"./ADEChallengeData2016/annotations/validation/\"\n",
    "\n",
    "FLOOR_ID = 4\n",
    "TRAIN_SAMPLES = 100000\n",
    "VAL_SAMPLES   = 20000\n",
    "N_JOBS = -1\n",
    "\n",
    "def process_image(img_path, ann_path, samples_per_image):\n",
    "    \"\"\"\n",
    "    Reads an image and annotation, and returns a sampled subset of features and labels.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        img = cv2.imread(img_path)\n",
    "        ann = cv2.imread(ann_path, 0)\n",
    "        \n",
    "        if img is None or ann is None:\n",
    "            return None, None\n",
    "\n",
    "        H, W, _ = img.shape\n",
    "        mask = (ann == FLOOR_ID).astype(np.int32)\n",
    "\n",
    "        rgb = img.reshape(-1, 3).astype(np.float32) / 255.0\n",
    "        labels = mask.reshape(-1)\n",
    "\n",
    "        xs, ys = np.meshgrid(np.arange(W), np.arange(H))\n",
    "        xs = xs.reshape(-1, 1) / W\n",
    "        ys = ys.reshape(-1, 1) / H\n",
    "        \n",
    "        features = np.hstack([rgb, xs, ys])\n",
    "\n",
    "        if len(labels) > samples_per_image:\n",
    "            idx = np.random.choice(len(labels), samples_per_image, replace=False)\n",
    "            return features[idx], labels[idx]\n",
    "        else:\n",
    "            return features, labels\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {img_path}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def load_data_parallel(image_paths, ann_paths, total_samples):\n",
    "    n_images = len(image_paths)\n",
    "    if n_images == 0: return np.array([]), np.array([])\n",
    "    \n",
    "    samples_per_image = max(1, total_samples // n_images)\n",
    "    \n",
    "    print(f\"Processing {n_images} images with {N_JOBS} jobs...\")\n",
    "    results = Parallel(n_jobs=N_JOBS)(delayed(process_image)(img, ann, samples_per_image) \n",
    "                                      for img, ann in zip(image_paths, ann_paths))\n",
    "    \n",
    "    X_list = [res[0] for res in results if res[0] is not None]\n",
    "    y_list = [res[1] for res in results if res[1] is not None]\n",
    "    \n",
    "    if not X_list:\n",
    "        return np.array([]), np.array([])\n",
    "        \n",
    "    X_all = np.vstack(X_list)\n",
    "    y_all = np.hstack(y_list)\n",
    "    \n",
    "    idx = np.random.permutation(len(X_all))\n",
    "    \n",
    "    if len(idx) > total_samples:\n",
    "        idx = idx[:total_samples]\n",
    "        \n",
    "    return X_all[idx], y_all[idx]\n",
    "\n",
    "\n",
    "train_images = sorted(glob.glob(TRAIN_IMG_DIR + \"*.jpg\"))[:50]\n",
    "train_annots = sorted(glob.glob(TRAIN_ANN_DIR + \"*.png\"))[:50]\n",
    "\n",
    "print(\"Loading Training Data...\")\n",
    "start_load = time.time()\n",
    "X_train, y_train = load_data_parallel(train_images, train_annots, TRAIN_SAMPLES)\n",
    "print(f\"Loaded {len(X_train)} samples in {time.time() - start_load:.2f}s\")\n",
    "\n",
    "val_images = sorted(glob.glob(VAL_IMG_DIR + \"*.jpg\"))[:20]\n",
    "val_annots = sorted(glob.glob(VAL_ANN_DIR + \"*.png\"))[:20]\n",
    "\n",
    "print(\"Loading Validation Data...\")\n",
    "X_val, y_val = load_data_parallel(val_images, val_annots, VAL_SAMPLES)\n",
    "\n",
    "# Train SVM\n",
    "print(\"Training SVM...\")\n",
    "svm = LinearSVC(C=1.0, max_iter=3000)\n",
    "\n",
    "start_train = time.time()\n",
    "svm.fit(X_train, y_train)\n",
    "train_time = time.time() - start_train\n",
    "\n",
    "# Inference\n",
    "print(\"Running Inference...\")\n",
    "start_test = time.time()\n",
    "y_pred = svm.predict(X_val)\n",
    "test_time = time.time() - start_test\n",
    "\n",
    "accuracy  = accuracy_score(y_val, y_pred)\n",
    "precision = precision_score(y_val, y_pred, zero_division=0)\n",
    "recall    = recall_score(y_val, y_pred, zero_division=0)\n",
    "\n",
    "print(\"\\n=== Optimized Method 2: RGB + (x,y), LinearSVC ===\")\n",
    "print(f\"Accuracy : {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall   : {recall:.4f}\")\n",
    "print(f\"Training time : {train_time:.4f}s\")\n",
    "print(f\"Inference time: {test_time:.4f}s\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
